# Serving a Custom Model on a Kubernetes or OpenShift Cluster

With IBM Watson NLP, IBM introduced a common library for natural language processing, document understanding, translation, and trust. IBM Watson NLP brings everything under one umbrella for consistency and ease of development and deployment. 

Follow the [tutorial](https://developer.ibm.com/tutorials/serve-custom-models-on-kubernetes-or-openshift/ to learn how to take a Watson NLP model that you trained in IBM Watson Studio and serve it on a Kubernetes or Red Hat OpenShift cluster. 

The model is packaged as a container image using the model builder. The container images can be used in the same way as the pretrained Watson NLP models, that is, specified as init containers of Watson NLP Runtime Pods.
